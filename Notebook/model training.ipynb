{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234c0c99-74fd-45c7-88aa-0ad5c1e71493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de085df-281d-48d5-93c9-5eff9c9d27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_utils.py\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def create_preprocessor(X):\n",
    "    \"\"\"\n",
    "    Returns a ColumnTransformer for numeric and categorical preprocessing\n",
    "    \"\"\"\n",
    "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61434038-c52f-4b3f-ac3e-779597543ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
      "0  female        group B           bachelor's degree      standard   \n",
      "1  female        group C                some college      standard   \n",
      "2  female        group B             master's degree      standard   \n",
      "3    male        group A          associate's degree  free/reduced   \n",
      "4    male        group C                some college      standard   \n",
      "\n",
      "  test_preparation_course  math_score  reading_score  writing_score  \\\n",
      "0                    none          72             72             74   \n",
      "1               completed          69             90             88   \n",
      "2                    none          90             95             93   \n",
      "3                    none          47             57             44   \n",
      "4                    none          76             78             75   \n",
      "\n",
      "   average_score  \n",
      "0      72.666667  \n",
      "1      82.333333  \n",
      "2      92.666667  \n",
      "3      49.333333  \n",
      "4      76.333333  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\karth\\OneDrive\\Desktop\\P2\\stud_eda.ipynb\")\n",
    "df = pd.read_csv(r\"C:\\Users\\karth\\OneDrive\\Desktop\\P2\\stud.csv\")  # Replace with your dataset\n",
    "df[\"average_score\"] = df[[\"math_score\", \"reading_score\", \"writing_score\"]].mean(axis=1)\n",
    "\n",
    "# Define the target column\n",
    "target_column = \"average_score\"\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# (Optional) Check the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be069362-acde-4d9f-bb68-24a4aeed5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libriries mse, mean square error, r2 , mean absolute, knn, decisoon tree, random forest, addabost, svr, liner regression, lasso, randamise search cv, cat boost, xg boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1774b6e4-a5cb-4a0e-b889-48c4384a93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data split data, standard scalar, encoding, column transformer, pre processor, trasormation by x coliumn by fit underscore transform , train test s#plit\n",
    "#80 20, evealuate ,=model t,p use mse, mae, r2 score,rmse adjusted r2, use linear regression , lasso, ridge, knn, radomforest, decision, xgb, cat and adaboost\n",
    "#evaluate train and test dataset, model performance for train and test create dataframe of mse, mae, r2 score,rmse adjusted r2 and select top 2 models by comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984e178-3cf0-43cf-8693-14318d65b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_utils.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def create_preprocessor(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Automatically creates a preprocessing pipeline for numeric and categorical features.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Input feature DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    preprocessor : ColumnTransformer\n",
    "        A fitted ColumnTransformer that handles numeric and categorical preprocessing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate column types\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Define transformations\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    # Combine into one preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79212d4b-9a9e-4ecf-bc9f-294ef5cfa84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                 ['math_score', 'reading_score',\n",
      "                                  'writing_score']),\n",
      "                                ('cat',\n",
      "                                 OneHotEncoder(handle_unknown='ignore',\n",
      "                                               sparse_output=False),\n",
      "                                 ['gender', 'race_ethnicity',\n",
      "                                  'parental_level_of_education', 'lunch',\n",
      "                                  'test_preparation_course'])])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\karth\\OneDrive\\Desktop\\P2\\preprocessing_utils.py\")  # path to where preprocessing_utils.py is saved\n",
    "\n",
    "import preprocessing_utils\n",
    "from importlib import reload\n",
    "reload(preprocessing_utils)\n",
    "\n",
    "preprocessor = preprocessing_utils.create_preprocessor(X)\n",
    "print(preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f62a34d1-d8cd-4185-9cf6-9a8f93d840de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['math_score', 'reading_score', 'writing_score']\n",
      "Categorical: ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numeric:\", numeric_features)\n",
    "print(\"Categorical:\", categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec53ac1f-11c7-491b-a4a3-8a7fdaad6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b38555-ace1-40a0-a64b-9eaa966b9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e153bff3-451f-4bc6-8332-49cba7e72c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "    \"CatBoost\": CatBoostRegressor(n_estimators=100, random_state=42, verbose=0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c12a3ed-254e-4e67-82af-55f625ccc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model     Train_MSE      Test_MSE     Train_MAE      Test_MAE  \\\n",
      "0  LinearRegression  2.657041e-28  2.904901e-28  1.491696e-14  1.529443e-14   \n",
      "2             Ridge  6.267424e-05  7.560537e-05  6.410010e-03  6.601822e-03   \n",
      "1             Lasso  1.112895e-02  1.217037e-02  8.428454e-02  8.658499e-02   \n",
      "7  GradientBoosting  1.814568e-01  9.196651e-01  3.363734e-01  5.495731e-01   \n",
      "8           XGBoost  3.246331e-03  9.813724e-01  4.059767e-02  5.543794e-01   \n",
      "5      RandomForest  9.049382e-02  1.280560e+00  1.903958e-01  5.248333e-01   \n",
      "9          CatBoost  1.359036e-01  1.983218e+00  2.993476e-01  6.524388e-01   \n",
      "4      DecisionTree  0.000000e+00  2.695000e+00  0.000000e+00  1.105000e+00   \n",
      "6          AdaBoost  2.549871e+00  4.080702e+00  1.258749e+00  1.424400e+00   \n",
      "3               KNN  5.031239e+00  9.309756e+00  1.760583e+00  2.255000e+00   \n",
      "\n",
      "   Train_R2   Test_R2    Train_RMSE     Test_RMSE  Train_AdjR2  Test_AdjR2  \n",
      "0  1.000000  1.000000  1.630043e-14  1.704377e-14     1.000000    1.000000  \n",
      "2  1.000000  1.000000  7.916707e-03  8.695135e-03     1.000000    1.000000  \n",
      "1  0.999944  0.999943  1.054938e-01  1.103194e-01     0.999944    0.999941  \n",
      "7  0.999090  0.995710  4.259775e-01  9.589917e-01     0.999081    0.995530  \n",
      "8  0.999984  0.995422  5.697658e-02  9.906424e-01     0.999984    0.995230  \n",
      "5  0.999546  0.994026  3.008219e-01  1.131619e+00     0.999542    0.993776  \n",
      "9  0.999319  0.990748  3.686510e-01  1.408268e+00     0.999312    0.990361  \n",
      "4  1.000000  0.987428  0.000000e+00  1.641646e+00     1.000000    0.986902  \n",
      "6  0.987215  0.980964  1.596832e+00  2.020075e+00     0.987086    0.980167  \n",
      "3  0.974774  0.956571  2.243042e+00  3.051189e+00     0.974519    0.954752  \n"
     ]
    }
   ],
   "source": [
    "def adjusted_r2(r2, n, p):\n",
    "    \"\"\"Adjusted R2 score\"\"\"\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Train metrics\n",
    "    n_train = X_train.shape[0]\n",
    "    p = X_train.shape[1]\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train_MSE\": mean_squared_error(y_train, y_train_pred),\n",
    "        \"Test_MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "        \"Train_MAE\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Test_MAE\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Train_R2\": train_r2,\n",
    "        \"Test_R2\": test_r2,\n",
    "        \"Train_RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Test_RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Train_AdjR2\": adjusted_r2(train_r2, n_train, p),\n",
    "        \"Test_AdjR2\": adjusted_r2(test_r2, X_test.shape[0], p)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"Test_R2\", ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f50307d0-62b2-463f-be70-fb3af31d314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 models based on Test R²:\n",
      "              Model  Test_R2      Test_MSE     Test_RMSE\n",
      "0  LinearRegression      1.0  2.904901e-28  1.704377e-14\n",
      "2             Ridge      1.0  7.560537e-05  8.695135e-03\n"
     ]
    }
   ],
   "source": [
    "top2_models = results_df.head(2)\n",
    "print(\"Top 2 models based on Test R²:\")\n",
    "print(top2_models[[\"Model\", \"Test_R2\", \"Test_MSE\", \"Test_RMSE\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b625a02-06ac-4a6e-a9b2-4b82bcf1a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2(r2, n, p):\n",
    "    \"\"\"Calculate Adjusted R2 score\"\"\"\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f6b787-7e2f-40d6-817f-729e13888a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    p = X_train.shape[1]\n",
    "    \n",
    "    # Metrics\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train_MSE\": mean_squared_error(y_train, y_train_pred),\n",
    "        \"Test_MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "        \"Train_MAE\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Test_MAE\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Train_R2\": r2_score(y_train, y_train_pred),\n",
    "        \"Test_R2\": r2_score(y_test, y_test_pred),\n",
    "        \"Train_RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Test_RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Train_AdjR2\": adjusted_r2(r2_score(y_train, y_train_pred), n_train, p),\n",
    "        \"Test_AdjR2\": adjusted_r2(r2_score(y_test, y_test_pred), n_test, p)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7f1c8e-8d34-4ab9-99d5-b5edeff33b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models evaluated:\n",
      "\n",
      "              Model     Train_MSE      Test_MSE     Train_MAE      Test_MAE  \\\n",
      "0  LinearRegression  2.657041e-28  2.904901e-28  1.491696e-14  1.529443e-14   \n",
      "2             Ridge  6.267424e-05  7.560537e-05  6.410010e-03  6.601822e-03   \n",
      "1             Lasso  1.112895e-02  1.217037e-02  8.428454e-02  8.658499e-02   \n",
      "7  GradientBoosting  1.814568e-01  9.196651e-01  3.363734e-01  5.495731e-01   \n",
      "8           XGBoost  3.246331e-03  9.813724e-01  4.059767e-02  5.543794e-01   \n",
      "5      RandomForest  9.049382e-02  1.280560e+00  1.903958e-01  5.248333e-01   \n",
      "9          CatBoost  1.359036e-01  1.983218e+00  2.993476e-01  6.524388e-01   \n",
      "4      DecisionTree  0.000000e+00  2.695000e+00  0.000000e+00  1.105000e+00   \n",
      "6          AdaBoost  2.549871e+00  4.080702e+00  1.258749e+00  1.424400e+00   \n",
      "3               KNN  5.031239e+00  9.309756e+00  1.760583e+00  2.255000e+00   \n",
      "\n",
      "   Train_R2   Test_R2    Train_RMSE     Test_RMSE  Train_AdjR2  Test_AdjR2  \n",
      "0  1.000000  1.000000  1.630043e-14  1.704377e-14     1.000000    1.000000  \n",
      "2  1.000000  1.000000  7.916707e-03  8.695135e-03     1.000000    1.000000  \n",
      "1  0.999944  0.999943  1.054938e-01  1.103194e-01     0.999944    0.999941  \n",
      "7  0.999090  0.995710  4.259775e-01  9.589917e-01     0.999081    0.995530  \n",
      "8  0.999984  0.995422  5.697658e-02  9.906424e-01     0.999984    0.995230  \n",
      "5  0.999546  0.994026  3.008219e-01  1.131619e+00     0.999542    0.993776  \n",
      "9  0.999319  0.990748  3.686510e-01  1.408268e+00     0.999312    0.990361  \n",
      "4  1.000000  0.987428  0.000000e+00  1.641646e+00     1.000000    0.986902  \n",
      "6  0.987215  0.980964  1.596832e+00  2.020075e+00     0.987086    0.980167  \n",
      "3  0.974774  0.956571  2.243042e+00  3.051189e+00     0.974519    0.954752  \n"
     ]
    }
   ],
   "source": [
    "results_df_sorted = results_df.sort_values(by=\"Test_R2\", ascending=False)\n",
    "print(\"All models evaluated:\\n\")\n",
    "print(results_df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db23643-b311-4324-bb72-6cda310a2942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 2 models based on Test R²:\n",
      "\n",
      "              Model  Test_R2      Test_MSE     Test_RMSE  Test_AdjR2\n",
      "0  LinearRegression      1.0  2.904901e-28  1.704377e-14         1.0\n",
      "2             Ridge      1.0  7.560537e-05  8.695135e-03         1.0\n"
     ]
    }
   ],
   "source": [
    "top2_models = results_df_sorted.head(2)\n",
    "print(\"\\nTop 2 models based on Test R²:\\n\")\n",
    "print(top2_models[[\"Model\", \"Test_R2\", \"Test_MSE\", \"Test_RMSE\", \"Test_AdjR2\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f841afb-5224-4084-babe-8553ef91f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results_df\n",
    "df_metrics = results_df.copy()\n",
    "\n",
    "# Normalize metrics (0-1)\n",
    "df_metrics['R2_score'] = df_metrics['Test_R2']  # already between 0-1\n",
    "df_metrics['AdjR2_score'] = df_metrics['Test_AdjR2']  # usually between 0-1\n",
    "df_metrics['RMSE_score'] = 1 / (1 + df_metrics['Test_RMSE'])  # higher is better\n",
    "\n",
    "# Composite score: average of normalized metrics\n",
    "df_metrics['Composite_Score'] = (df_metrics['R2_score'] + df_metrics['AdjR2_score'] + df_metrics['RMSE_score']) / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6fc9df9-ccd5-49a0-bd48-26732821617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 models using composite score of R2, AdjR2, and RMSE:\n",
      "\n",
      "              Model  Test_R2  Test_AdjR2     Test_RMSE  Composite_Score\n",
      "0  LinearRegression      1.0         1.0  1.704377e-14         1.000000\n",
      "2             Ridge      1.0         1.0  8.695135e-03         0.997126\n"
     ]
    }
   ],
   "source": [
    "df_metrics_sorted = df_metrics.sort_values(by=\"Composite_Score\", ascending=False)\n",
    "top2_models_multi = df_metrics_sorted.head(2)\n",
    "\n",
    "print(\"Top 2 models using composite score of R2, AdjR2, and RMSE:\\n\")\n",
    "print(top2_models_multi[['Model', 'Test_R2', 'Test_AdjR2', 'Test_RMSE', 'Composite_Score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eada002-adae-4b8d-9a9c-eba4866d459d",
   "metadata": {},
   "source": [
    "Combines multiple aspects of model performance.\n",
    "\n",
    "Avoids choosing a model with high R² but very high RMSE (overfitting).\n",
    "\n",
    "Adjusted R² penalizes models with too many features → prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fe72d-19d1-42a0-b704-1ee85a7eba88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
